{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 00:22:46.461854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-01-20 00:22:46.461881: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras.utils as ku\n",
    "import keras.layers as kl\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "#from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dense, LSTM, Conv2D, Reshape, dot, Lambda, Dropout, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from itertools import islice\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.models import model_from_json\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras_preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import math\n",
    "import random\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from datetime import *\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.backend import int_shape\n",
    "pd.set_option('display.max_colwidth',25)\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.layers import concatenate\n",
    "#K.clear_session()\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import pathlib\n",
    "rando_seed = 1234\n",
    "np.random.seed(rando_seed)\n",
    "#os.chdir('/media/alex/easystore/ids_monthly/BLM_images/2014_11_12')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of Model - Confusion Matrix Plot\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['tweet_id', 'date', 'text', 'support', 'hashtags', 'users', 'urls', 'media_urls', 'nfollowers', 'nfriends', 'file_name', 'path']\n",
    "\n",
    "#DATA = pd.read_csv('./meta_image_dataset_2020.csv', dtype = {'doc_id':str, 'picfiles':str,'label':int})\n",
    "DATA = pd.read_csv('./elections_june21.csv', dtype = {'doc_id':str, 'picfiles':str,'label':str})\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['label'] = DATA['label'].map(str)\n",
    "DATA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.groupby('label').count()\n",
    "# pie chart / bar chart to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = DATA.dropna(subset=['label'])\n",
    "len(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be divisible by batch size (50)\n",
    "\n",
    "remove_n = 31\n",
    "drop_indices = np.random.choice(DATA.index, remove_n, replace=False)\n",
    "DATA = DATA.drop(drop_indices)\n",
    "len(DATA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data\n",
    "\n",
    "DATA = DATA.sample(frac=1, random_state=1234).reset_index(drop=True)\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data used to check for overfitting\n",
    "\n",
    "val_data = DATA.sample(n=500, replace=False, weights=None, random_state=1234, axis=None)\n",
    "DATA = DATA.drop(val_data.index)\n",
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DATA.sample(n=500, replace=False, weights=None, random_state=1234, axis=None)\n",
    "#test_data = test_data.sample(n=50, replace=False, weights=None, random_state=1234, axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DATA.drop(test_data.index)\n",
    "display(\"Length of val data:\", len(val_data))\n",
    "train_data.head()\n",
    "train_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie charts for each data set\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "train_ls = [train_data['label'].value_counts()]\n",
    "test_ls = [test_data['label'].value_counts()]\n",
    "val_ls = [val_data['label'].value_counts()]\n",
    "\n",
    "df['train'] = train_ls[0]\n",
    "df['val'] = val_ls[0]\n",
    "df['test'] = test_ls[0]\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = test_data['label'].value_counts()\n",
    "s.plot(kind='pie', title=\"Test Set\", figsize=(5, 5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/media/alex/easystore/ids_monthly/BLM_images/apsa_sample3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re: generators with multiple inputs\n",
    "\n",
    "#trainer_path = 'train/'\n",
    "#im_size = 28\n",
    "img_width, img_height = 96, 96\n",
    "batch_size = 50\n",
    "\n",
    "input_imgen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "def text_generator(a,labs, n):\n",
    "    while True:\n",
    "         for i in range(a.shape[0] // n):\n",
    "            d2 = a[n*i:n*(i+1)]\n",
    "            y_text = labs[n*i:n*(i+1)]\n",
    "            yield d2, y_text       \n",
    "            \n",
    "def multi_input_generator(df, x_image, y_image, x_txt, y_txt, b_size): \n",
    "    t1 = input_imgen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory = './labim_all',\n",
    "        x_col = x_image,\n",
    "        y_col = y_image,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=b_size,\n",
    "        class_mode='categorical',\n",
    "        validate_filenames=False)\n",
    "    \n",
    "    t2 = text_generator(a=x_txt, labs = y_txt, n=b_size)\n",
    "    \n",
    "    while True:\n",
    "        d1,y = t1.next()\n",
    "        d1 = np.expand_dims(d1, axis = 0)\n",
    "        d2, y_text = t2.__next__()\n",
    "        yield [d2, d1[0]], [y_text, y]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "###### TEXT PRE-PROCESSING ###############################\n",
    "\n",
    "\n",
    "# PARAMETERS\n",
    "#MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NUM_WORDS = 25\n",
    "EMBEDDING_DIM = 100\n",
    "#VALIDATION_SPLIT = 0.2\n",
    "\n",
    "\n",
    "# SUBSET TO ONLY DATA AND LABELS\n",
    "train_data_text = train_data[['features','label']]\n",
    "train_labels_text = train_data['label'].values\n",
    "train_data_text.head()\n",
    "\n",
    "val_data_text = val_data[['features','label']]\n",
    "val_labels_text = val_data['label'].values\n",
    "val_data_text.head()\n",
    "\n",
    "test_data_text = test_data[['features','label']]\n",
    "test_labels_text = test_data['label'].values\n",
    "test_data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizers for training text data\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(train_data_text['features'].values)\n",
    "sequences = tokenizer.texts_to_sequences(train_data_text['features'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_data_text = pad_sequences(sequences)\n",
    "train_labels_text = ku.to_categorical(np.asarray(train_labels_text))\n",
    "\n",
    "print('Shape of train data tensor:', train_data_text.shape)\n",
    "print('Shape of train label tensor:', train_labels_text.shape)\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# tokenizers for val text data\n",
    "\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, lower=True,split=' ')\n",
    "#tokenizer.fit_on_texts(val_data_text['text'].values)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_data_text['features'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique val tokens.' % len(word_index))\n",
    "\n",
    "val_data_text = pad_sequences(val_sequences)\n",
    "val_labels_text = ku.to_categorical(np.asarray(val_labels_text))\n",
    "\n",
    "#print('Shape of val data tensor:', val_data_text.shape)\n",
    "#print('Shape of val label tensor:', val_labels_text.shape)\n",
    "\n",
    "##########################################################################\n",
    "# tokenizers for test text data\n",
    "\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, lower=True,split=' ')\n",
    "#tokenizer.fit_on_texts(val_data_text['text'].values)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data_text['features'].values)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique val tokens.' % len(word_index))\n",
    "\n",
    "test_data_text = pad_sequences(test_sequences)\n",
    "test_labels_text = ku.to_categorical(np.asarray(test_labels_text))\n",
    "\n",
    "display('Shape of test data tensor:', test_data_text.shape)\n",
    "display('Shape of test label tensor:', test_labels_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of val data tensor:', val_data_text.shape)\n",
    "print('Shape of val label tensor:', val_labels_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = multi_input_generator(df = train_data, x_image='picfiles', y_image='label',\n",
    "                                    x_txt=train_data_text, y_txt=train_labels_text, b_size=batch_size)\n",
    "\n",
    "val_generator = multi_input_generator(df = val_data, x_image='picfiles', y_image='label',\n",
    "                                    x_txt=val_data_text, y_txt=val_labels_text, b_size=batch_size)\n",
    "\n",
    "test_generator = multi_input_generator(df = test_data, x_image='picfiles', y_image='label',\n",
    "                                    x_txt=test_data_text, y_txt=test_labels_text, b_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsetsize = len(train_data)\n",
    "display('Number of training observations: ' + str(trainsetsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsetsize = len(val_data)\n",
    "display('Number of val observations: ' + str(valsetsize))\n",
    "\n",
    "testsetsize = len(test_data)\n",
    "display('Number of test observations: ' + str(testsetsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading embeddings from Stanford NLP\n",
    "# Good rundown of source code: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "# First, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print(\"Loading embeddings.\")\n",
    "\n",
    "embeddings_index = dict()\n",
    "#texts = []\n",
    "f = open('glove.6B.100d.txt', errors='ignore')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "#    texts.append(word)\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point we can leverage our embedding_index dictionary and our word_index to compute our embedding matrix:\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=25,\n",
    "                            trainable=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image model\n",
    "\n",
    "image_model = VGG16(include_top=False, input_shape = (img_width, img_height, 3), weights='imagenet', pooling=None, classes=2)\n",
    "\n",
    "for layer in image_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "########## MODEL CONSTRUCTION #############################################\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dot\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(None, ), dtype='int64')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x_text = Conv1D(32, kernel_size = 5, activation=\"relu\", padding = 'same')(embedded_sequences)\n",
    "x_text = MaxPooling1D(5)(x_text)\n",
    "x_text = Conv1D(32, kernel_size = 5, activation=\"relu\", padding = 'same')(x_text)\n",
    "x_text = GlobalMaxPooling1D()(x_text)\n",
    "x_text = Dense(16, activation=\"relu\")(x_text)\n",
    "#x_text = Dropout(0.5)(x_text)\n",
    "preds = Dense(2, activation='relu')(x_text)\n",
    "\n",
    "\n",
    "\n",
    "# Adding custom Layers\n",
    "\n",
    "x_image = image_model.output\n",
    "\n",
    "x_image = Conv2D(3, 1, activation=\"relu\", padding = 'same')(x_image)\n",
    "x_image = MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x_image)\n",
    "x_image = Conv2D(3, 1, activation=\"relu\", padding = 'same')(x_image)\n",
    "x_image = MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x_image)\n",
    "x_image = Conv2D(3, 1, activation=\"relu\", padding = 'same')(x_image)\n",
    "x_image = MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "img_predictions = Dense(2, activation=\"relu\")(x_image)\n",
    "\n",
    "\n",
    "#merged = Dot(axes=1)([preds, img_predictions])\n",
    "\n",
    "merged = Concatenate()([preds, img_predictions])\n",
    "\n",
    "# We stack densely-connected network on top\n",
    "x = Dense(64, activation='relu')(merged)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dense(4, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "main_output = Dense(2, activation='sigmoid', name = 'main_output')(x)\n",
    "\n",
    "\n",
    "\n",
    "# Defining a model with two inputs and one outputs\n",
    "elections_model = Model([sequence_input, image_model.input], [main_output])\n",
    "\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "\n",
    "print(\"ROMA VICTOR!\")\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-5, momentum=0.95, nesterov=True, clipvalue=.5)\n",
    "elections_model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics = ['categorical_accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = elections_model.fit(train_generator,\n",
    "          steps_per_epoch=trainsetsize//batch_size,\n",
    "                    class_weight = None,\n",
    "                        epochs = 50,\n",
    "                        validation_data = val_generator,\n",
    "                        validation_steps = valsetsize//batch_size)\n",
    "                        #use_multiprocessing=True,\n",
    "                        #shuffle=False)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics_ti = pd.read_csv('training_metrics.csv')\n",
    "training_metrics_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = training_metrics_ti['accuracy']\n",
    "val_acc = training_metrics_ti['val_accuracy']\n",
    "\n",
    "loss = training_metrics_ti['loss']\n",
    "val_loss = training_metrics_ti['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "#plt.savefig(train_file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle        \n",
    "# create an iterator object with write permission - model.pkl\n",
    "\n",
    "\n",
    "#elections_model.save('elections_model916.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 00:25:09.829000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-01-20 00:25:09.829031: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-20 00:25:09.829044: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gl3185.arc-ts.umich.edu): /proc/driver/nvidia/version does not exist\n",
      "2023-01-20 00:25:09.829681: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 96, 96, 64)   1792        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 96, 96, 64)   36928       ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 48, 48, 64)   0           ['block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 48, 48, 128)  73856       ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 48, 48, 128)  147584      ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 24, 24, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 24, 24, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 24, 24, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 24, 24, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 12, 12, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 12, 12, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 12, 12, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 12, 12, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 6, 6, 512)    0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 6, 6, 512)    2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 6, 6, 512)    2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 6, 6, 512)    2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 3, 3, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 3, 3, 3)      1539        ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    2600        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 3)     0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, None, 32)     16032       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 3, 3, 3)      12          ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, None, 32)    0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 3)     0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, None, 32)     5152        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 3, 3, 3)      12          ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 32)          0           ['conv1d_3[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 3)     0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           528         ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 27)           0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 2)            34          ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 2)            56          ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4)            0           ['dense_9[0][0]',                \n",
      "                                                                  'dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           320         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 32)           2080        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 16)           528         ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            136         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 4)            36          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 2)            10          ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,743,763\n",
      "Trainable params: 26,475\n",
      "Non-trainable params: 14,717,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('elections_model916.h5')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator1 = multi_input_generator(df = test_data, x_image='picfiles', y_image='label',\n",
    "                                    x_txt=test_data_text, y_txt=test_labels_text, b_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "for i, tweet in enumerate(test_generator1):\n",
    "        \n",
    "        print(\"Image Number: \", i)\n",
    "    \n",
    "        print(img)\n",
    "        \n",
    "        if i >= n:\n",
    "            break\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 499\n",
    "train_labels0 = []\n",
    "train_labels1 = []\n",
    "train_preds = []\n",
    "\n",
    "\n",
    "for i, tweet in enumerate(train_generator):\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "            \n",
    "        print(\"Image Number: \", i)\n",
    "\n",
    "    pred1 = model1.predict(tweet[0], use_multiprocessing = False)\n",
    "\n",
    "    train_preds.append(pred1)\n",
    "\n",
    "    train_labels0.append(tweet[1][0])\n",
    "    train_labels1.append(tweet[1][1])\n",
    "\n",
    "    if i >= n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 499\n",
    "labels0 = []\n",
    "labels1 = []\n",
    "preds = []\n",
    "\n",
    "\n",
    "for i, tweet in enumerate(test_generator):\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "            \n",
    "        print(\"Image Number: \", i)\n",
    "\n",
    "    pred1 = model1.predict(tweet[0], use_multiprocessing = False)\n",
    "\n",
    "    preds.append(pred1)\n",
    "\n",
    "    labels0.append(tweet[1][0])\n",
    "    labels1.append(tweet[1][1])\n",
    "\n",
    "    if i >= n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_predictions = []\n",
    "# Convert to an array of binary values\n",
    "\n",
    "for i in train_preds:\n",
    "    \n",
    "    train_predictions.append(np.argmax(i, axis=1))\n",
    "    \n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_labs0 = []\n",
    "\n",
    "for i in train_labels0:\n",
    "    \n",
    "    train_labs0.append(np.argmax(i, axis=1))\n",
    "\n",
    "\n",
    "train_labs0[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs1 = []\n",
    "\n",
    "for i in train_labels1:\n",
    "    \n",
    "    train_labs1.append(np.argmax(i, axis=1))\n",
    "\n",
    "\n",
    "train_labs1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_final = np.concatenate(train_predictions).ravel().tolist()\n",
    "train_labs0_final = np.concatenate(train_labs0).ravel().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labs1_final = np.concatenate(train_labs1).ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Grab true labels from the validation generator\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "\n",
    "# labels = ['W', 'NW']\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(train_labs0_final, train_predictions_final, labels = [0, 1], sample_weight=None)\n",
    "#print(conf_mat)\n",
    "\n",
    "plot_confusion_matrix(conf_mat, classes=[0, 1],\n",
    "                      title='Confusion matrix, with normalization', normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
